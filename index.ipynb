{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Beautiful Soup - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Now that you've read and seen some docmentation regarding the use of Beautiful Soup, its time to practice and put that to work! In this lab you'll formalize some of our example code into functions and scrape the lyrics from an artist of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "You will be able to:\n",
    "* Scrape Static webpages\n",
    "* Select specific elements from the DOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Scraping\n",
    "\n",
    "Write a function to collect the links to each of the song pages from a given artist page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading https://files.pythonhosted.org/packages/10/ed/7e8b97591f6f456174139ec089c769f89a94a1a4025fe967691de971f314/bs4-0.0.1.tar.gz\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/0a/47fdf541c97fd9b6a610cb5fd518175308a7cc60569962e776ac52420387/beautifulsoup4-4.6.3-py3-none-any.whl (90kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 9.2MB/s ta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: bs4\n",
      "  Running setup.py bdist_wheel for bs4 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/steeznation16/.cache/pip/wheels/a0/b0/b2/4f80b9456b87abedbc0bf2d52235414c3467d8889be38dd472\n",
      "Successfully built bs4\n",
      "Installing collected packages: beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.6.3 bs4-0.0.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_song_links(artist_page_url):\n",
    "\n",
    "    url = artist_page_url\n",
    "\n",
    "    html_page = requests.get(url) #Make a get request to retrieve the page\n",
    "    soup = BeautifulSoup(html_page.content, 'html.parser') #Pass the page contents to beautiful soup for parsing\n",
    "\n",
    "\n",
    "    #The example from our lecture/reading\n",
    "    data = [] #Create a storage container\n",
    "\n",
    "    #Get album divs\n",
    "    albums = soup.find_all(\"div\", class_=\"album\")\n",
    "    for album_n in range(len(albums)):\n",
    "        #On the last album, we won't be able to look forward\n",
    "        if album_n == len(albums)-1:\n",
    "            cur_album = albums[album_n]\n",
    "            album_songs = cur_album.findNextSiblings('a')\n",
    "            for song in album_songs:\n",
    "                page = song.get('href')\n",
    "                title = song.text\n",
    "                album = cur_album.text\n",
    "                data.append((title, page, album))\n",
    "        else:\n",
    "            cur_album = albums[album_n]\n",
    "            next_album = albums[album_n+1]\n",
    "            saca = cur_album.findNextSiblings('a') #songs after current album\n",
    "            sbna = next_album.findPreviousSiblings('a') #songs before next album\n",
    "            album_songs = [song for song in saca if song in sbna] #album songs are those listed after the current album but before the next one!\n",
    "            for song in album_songs:\n",
    "                page = song.get('href')\n",
    "                title = song.text\n",
    "                album = cur_album.text\n",
    "                data.append((title, page, album))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'albums' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-859fb6c4eaf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#The example from our lecture/reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#Create a storage container\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0malbum_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malbums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m#On the last album, we won't be able to look forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0malbum_n\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malbums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'albums' is not defined"
     ]
    }
   ],
   "source": [
    "#Starter Code\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://www.azlyrics.com/m/muse.html#60785' #Put the URL of your AZLyrics Artist Page here!\n",
    "\n",
    "html_page = requests.get(url) #Make a get request to retrieve the page\n",
    "soup = BeautifulSoup(html_page.content, 'html.parser') #Pass the page contents to beautiful soup for parsing\n",
    "\n",
    "grab_song_links()\n",
    "\n",
    "# #The example from our lecture/reading\n",
    "# data = [] #Create a storage container\n",
    "# for album_n in range(len(albums)):\n",
    "#     #On the last album, we won't be able to look forward\n",
    "#     if album_n == len(albums)-1:\n",
    "#         cur_album = albums[album_n]\n",
    "#         album_songs = cur_album.findNextSiblings('a')\n",
    "#         for song in album_songs:\n",
    "#             page = song.get('href')\n",
    "#             title = song.text\n",
    "#             album = cur_album.text\n",
    "#             data.append((title, page, album))\n",
    "#     else:\n",
    "#         cur_album = albums[album_n]\n",
    "#         next_album = albums[album_n+1]\n",
    "#         saca = cur_album.findNextSiblings('a') #songs after current album\n",
    "#         sbna = next_album.findPreviousSiblings('a') #songs before next album\n",
    "#         album_songs = [song for song in saca if song in sbna] #album songs are those listed after the current album but before the next one!\n",
    "#         for song in album_songs:\n",
    "#             page = song.get('href')\n",
    "#             title = song.text\n",
    "#             album = cur_album.text\n",
    "#             data.append((title, page, album))\n",
    "# data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Scraping\n",
    "Write a secondary function that scrapes the lyrics for each song page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remember to open up the webpage in a browser and control-click/right-click and go to inspect!\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "#Example page\n",
    "url = 'https://www.azlyrics.com/lyrics/lilyallen/sheezus.html'\n",
    "\n",
    "\n",
    "html_page = requests.get(url)\n",
    "soup = BeautifulSoup(html_page.content, 'html.parser')\n",
    "soup.prettify()[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesizing\n",
    "Create a script using your two functions above to scrape all of the song lyrics for a given artist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this block for your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing\n",
    "Generate two bar graphs to compare lyrical changes for the artist of your chose. For example, the two bar charts could compare the lyrics for two different songs or two different albums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this block for your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level - Up\n",
    "\n",
    "Think about how you structured the data from your web scraper. Did you scrape the entire song lyrics verbatim? Did you simply store the words and their frequency counts, or did you do something else entirely? List out a few different options for how you could have stored this data. What are advantages and disadvantages of each? Be specific and think about what sort of analyses each representation would lend itself to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this block for your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You've now practiced your Beautiful Soup knowledge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
